{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff947d1",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is a natural language processing (NLP) technique used to determine the sentiment of a piece of text. Sentiment analysis involves analyzing the text to determine whether it is positive, negative, or neutral. Sentiment analysis can be used to analyze social media posts, customer reviews, and other types of user-generated content.\n",
    "\n",
    "Sentiment analysis is a natural language processing (NLP) technique used to identify and categorize emotions or opinions expressed in text. It is commonly applied to determine whether a piece of writing—such as a review, tweet, or customer feedback—is positive, negative, or neutral. By analyzing linguistic features like word choice, tone, and context, sentiment analysis enables organizations to understand public perception, monitor brand reputation, and gain insights from large volumes of textual data. Techniques range from rule-based models using lexicons to advanced machine learning and deep learning approaches that capture complex patterns and context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a14a45",
   "metadata": {},
   "source": [
    "## 1. SentiStrength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf2d120",
   "metadata": {},
   "source": [
    "## 2. VADER\n",
    "\n",
    "Vader (Valence Aware Dictionary and sEntiment Reasoner) is a rule-based sentiment analysis tool that is specifically designed for analyzing social media texts. Vader is a pre-trained sentiment analysis model that provides a sentiment score for a given text.\n",
    "\n",
    "Vader uses a dictionary of words and rules to determine the sentiment of a piece of text. It uses a valence score for each word to determine its positivity or negativity. The valence score ranges from -4 to +4, with -4 being the most negative and +4 being the most positive.\n",
    "\n",
    "Vader also takes into account the intensity of the sentiment, which can be determined by capitalization and punctuation. For example, all caps or exclamation marks can indicate a stronger sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0a799",
   "metadata": {},
   "source": [
    "## 3. TextBlob\n",
    "\n",
    "TextBlob is a Python library used for Natural Language Processing (NLP). It relies on NLTK (Natural Language Toolkit). When you give it a sentence, it gives back two things: polarity and subjectivity.\n",
    "\n",
    "The polarity score ranges from -1 to 1. A score of -1 means the words are super negative, like “disgusting” or “awful.” A score of 1 means the words are super positive, like “excellent” or “best.”\n",
    "\n",
    "Subjectivity score, on the other hand, goes from 0 to 1. If it’s close to 1, it means the sentence has a lot of personal opinion instead of just facts.\n",
    "\n",
    "For my project, I was mostly interested in the polarity score because I wasn’t focusing on facts. TextBlob can do a lot of other things too, like figuring out noun phrases, tagging parts of speech, breaking down words, and more. So, I didn’t use the subjectivity score in my project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689ab96",
   "metadata": {},
   "source": [
    "## 4. SentiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e817e-3547-4001-827a-269657d6f896",
   "metadata": {},
   "source": [
    "# Lexical Sentiment Analysis using SentiStrength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5473a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bde56246-ff5d-4938-9584-d1f2160712cd",
   "metadata": {},
   "source": [
    "Sentiment analysis is a powerful technique that allows us to automatically understand the opinions, emotions, and attitudes expressed in written text. This tutorial will guide you through the process of conducting a robust sentiment analysis on social media data, specifically focusing on Twitter data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea417ac-3883-48cf-b4fa-a7034fdf3361",
   "metadata": {},
   "source": [
    "We'll begin by introducing sentiment analysis, its origins, and its importance in today's digital landscape. Sentiment analysis, also known as opinion mining or emotion analysis, is the automated process of interpreting and classifying the underlying sentiments or emotions in text data. This technique has its roots in computer science but has since been widely adopted across various disciplines, including management, social sciences, and linguistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a623048-69d3-4963-836f-fc1e1052b5b1",
   "metadata": {},
   "source": [
    "The advent of social media has significantly increased the value and relevance of sentiment analysis. Platforms like Twitter have become powerful channels for individuals to express their opinions, emotions, and sentiments on a wide range of topics. Leveraging this wealth of user-generated content requires constant monitoring and analysis, making sentiment analysis an invaluable tool for businesses, governments, and researchers alike.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba49d1-e923-45e9-ba8b-3962f40d6e2b",
   "metadata": {},
   "source": [
    "In this tutorial, we'll follow a structured sentiment analysis process that covers the essential steps from topic identification to data visualization. We'll start by defining our research question and identifying the relevant data source (in this case, Twitter). Next, we'll discuss techniques for data collection, cleaning, and preprocessing to ensure high-quality input for our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dfdb5-5fe3-4d60-92b9-274553dd23ec",
   "metadata": {},
   "source": [
    "Once our data is ready, we'll introduce a valuable tool called SentiStrength, a widely used and well-established sentiment analysis library. SentiStrength has been employed by researchers across various domains, and its effectiveness has been demonstrated in numerous scholarly publications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2639fa6-f4f4-4b60-b3ca-a598f14ca01c",
   "metadata": {},
   "source": [
    "After applying SentiStrength to our Twitter data, we'll explore techniques for visualizing and interpreting the sentiment analysis results. This will involve creating insightful visualizations that can effectively communicate the key findings and insights derived from the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668d1e1-dcae-4735-93b0-988c4e0d049f",
   "metadata": {},
   "source": [
    "Throughout the tutorial, we'll address common challenges and considerations in sentiment analysis, such as handling irony, sarcasm, and implicit sentiment cues. We'll also discuss best practices for ensuring the accuracy and reliability of our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ed383-430f-49f5-bea1-52260a8cad4f",
   "metadata": {},
   "source": [
    "By the end of this tutorial, you'll have a solid understanding of the sentiment analysis process and the skills necessary to conduct high-quality sentiment analysis on social media data, particularly Twitter data. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992b153-282e-4014-9863-1c7a1a6da725",
   "metadata": {},
   "source": [
    "## Tweets Sentiment analysis (Sentistrengh )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf81d9-ac1c-452b-8bcc-d4ce4a83744d",
   "metadata": {},
   "source": [
    "SentiStrength is a powerful sentiment analysis tool that is freely available for academic research purposes. It can be accessed online through a live demo or downloaded (for Windows only) from the official website at http://sentistrength.wlv.ac.uk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b0050-fbe4-4c9f-9379-fcf5601a2585",
   "metadata": {},
   "source": [
    "At its core, SentiStrength is a lexicon-based sentiment classifier that compares social media text against a predefined lexicon of sentiment-bearing words and phrases. The program assigns sentiment scores ranging from -5 to +5, with positive numbers indicating favorable attitudes and negative numbers indicating negative attitudes. This approach is inspired by psychological research suggesting that human emotions can simultaneously exhibit both positive and negative sentiments, commonly known as mixed emotions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eb2a9-731c-4b90-8366-58b2726a1a22",
   "metadata": {},
   "source": [
    "One of the key strengths of SentiStrength is its ability to provide separate sentiment scores for each word within a sentence, allowing for a more granular analysis of the overall sentiment strength. The program's lexicon comprises 1,125 words and 1,364 word stems, each with an associated positive or negative sentiment score. For example, the word \"ailing\" has a score of -3 in the lexicon, suggesting a moderate negative sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71c800-b266-48ed-9409-7f75750c26c3",
   "metadata": {},
   "source": [
    "SentiStrength employs a range of sophisticated techniques to enhance its sentiment analysis capabilities. It accounts for negation, where positive terms preceded by negating words (e.g., \"not,\" \"don't\") have their sentiment flipped, and negative terms are neutralized. Additionally, the program considers booster words like \"very\" and \"extremely,\" which can amplify the sentiment strength of the following word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a703916-9a66-481a-971b-8d27adb3f102",
   "metadata": {},
   "source": [
    "The tool also incorporates rules for handling questions, idioms, spelling corrections, and punctuation, as well as rules specific to computer-mediated communication methods of expressing sentiment, such as emoticons. SentiStrength maintains a list of emoticons with associated sentiment strength scores, further enhancing its ability to accurately interpret sentiment in social media text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b975721-902e-4a11-9677-d7c87cfd7143",
   "metadata": {},
   "source": [
    "One of the notable advantages of SentiStrength is its speed and transparency. It can process up to 14,000 tweets per second on a standard PC and provides insights into how its scores were calculated. Additionally, SentiStrength supports multiple languages, making it a versatile tool for sentiment analysis across various linguistic contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71671e90",
   "metadata": {},
   "source": [
    "| Feature                   | **SentiStrength**                                    | **VADER**                                     | **TextBlob**                              | **SentiWordNet**                                |\n",
    "| ------------------------- | ---------------------------------------------------- | --------------------------------------------- | ----------------------------------------- | ----------------------------------------------- |\n",
    "| **Type**                  | Lexicon + Rule-based                                 | Lexicon + Rule-based (social-media optimized) | Lexicon + Rule-based                      | Lexicon-based (WordNet sentiment scores)        |\n",
    "| **Output Format**         | Two scores: +1 to +5 (positive), -1 to -5 (negative) | Compound (-1 to 1), with pos/neu/neg scores   | Polarity (-1 to 1), Subjectivity (0 to 1) | Positive, Negative, Objective scores (0 to 1)   |\n",
    "| **Language Support**      | English                                              | English                                       | English                                   | English (via WordNet)                           |\n",
    "| **Handles Negation**      | Yes                                                  | Yes                                           | Basic                                     | No (relies on word-level sentiment)             |\n",
    "| **Handles Emojis/Slang**  | Limited                                              | Very good                                     | Poor                                      | None                                            |\n",
    "| **Context Awareness**     | Limited                                              | Limited                                       | Very limited                              | None (word-level only)                          |\n",
    "| **Customizability**       | Yes (custom lexicons)                                | Limited                                       | Limited                                   | Moderate (can modify sentiment scores manually) |\n",
    "| **Ease of Use in Python** | Requires Java or wrapper (`senti` or `senticlass`)   | Very easy (`nltk.sentiment`)                  | Very easy (`textblob` package)            | Moderate (`nltk.corpus.sentiwordnet`)           |\n",
    "| **Use Cases**             | Short texts, informal text, social media             | Social media, tweets, short texts             | General-purpose text analysis             | Word-level sentiment scoring, academic research |\n",
    "| **License**               | Free for academic use                                | MIT                                           | MIT                                       | Open (WordNet-compatible license)               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8823138-01cb-4116-8fdd-cbf4c9326b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd96c42-f685-43e0-9d4f-591dafe065af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install sentistrength\n",
    "#! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f214e02-eaf5-4c28-b206-7a837f9a2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentistrength import PySentiStr\n",
    "senti = PySentiStr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de30d18b-87a4-4418-bc61-223b71bc5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti.setSentiStrengthPath('jar_datei/SentiStrength.jar') # Note: Provide absolute path instead of relative path\n",
    "senti.setSentiStrengthLanguageFolderPath('SentiStrengthData/') # Note: Provide absolute path instead of relative path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ce0c854-a127-4afa-82c3-1e65095b56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pysenti\n",
    "\n",
    "s = senti.getSentiment('What a horrible terrible day', score='dual')\n",
    "# SentiResult(positive=2, negative=-1, neutral=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51b5994f-7c53-4668-91ca-5c9af909254d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, -1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = senti.getSentiment('What a lovely positive day', score='dual')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d06f025c-d7fd-4bfb-8108-977ef61a42c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 -1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(result[0][0]) + ' ' + str(result[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc03e987-6277-4d6f-a2e7-6517f98a8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seniment(text):\n",
    "    result = senti.getSentiment(text, score='dual')\n",
    "    return str(result[0][0]) + ' ' + str(result[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e46e78-0303-49f7-8617-39d305adef84",
   "metadata": {},
   "source": [
    "Example use single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2f8e808-fc58-4cac-83cc-502ad6bda8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "result1 = senti.getSentiment('What a lovely day')\n",
    "print(result1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f659e88-8e6f-4bbe-aef6-4d981b2811a5",
   "metadata": {},
   "source": [
    "Example use (List of string or panda series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aef88ce5-81df-4a6e-a459-b42df0b34aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -1]\n",
      "[(2, -1), (1, -2)]\n",
      "[1, -1]\n",
      "[(2, -1, 1), (1, -2, -1)]\n"
     ]
    }
   ],
   "source": [
    "from sentistrength import PySentiStr\n",
    "senti = PySentiStr()\n",
    "senti.setSentiStrengthPath('jar_datei/SentiStrength.jar') # Note: Provide absolute path instead of relative path\n",
    "senti.setSentiStrengthLanguageFolderPath('SentiStrengthData/') # Note: Provide absolute path instead of relative path\n",
    "str_arr = ['What a lovely day', 'What a bad day']\n",
    "result = senti.getSentiment(str_arr, score='scale')\n",
    "print(result)\n",
    "\n",
    "# OR, if you want dual scoring (a score each for positive rating and negative rating)\n",
    "result2 = senti.getSentiment(str_arr, score='dual')\n",
    "print(result2)\n",
    "\n",
    "# OR, if you want binary scoring (1 for positive sentence, -1 for negative sentence)\n",
    "result2 = senti.getSentiment(str_arr, score='binary')\n",
    "print(result2)\n",
    "\n",
    "# OR, if you want trinary scoring (a score each for positive rating, negative rating and neutral rating)\n",
    "result2 = senti.getSentiment(str_arr, score='trinary')\n",
    "print(result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77a43f55-bdb3-45ed-b347-39269d369bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d626bc52-4f56-4572-b3a0-767a807d5b22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 728, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutil/SentiStrengthData_DE/_EmotionLookupTable_v5_SOURCE.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\GESIS\\MHcontent\\test4\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\GESIS\\MHcontent\\test4\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\GESIS\\MHcontent\\test4\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\GESIS\\MHcontent\\test4\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 1 fields in line 728, saw 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"util/SentiStrengthData_DE/_EmotionLookupTable_v5_SOURCE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd53230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   ############\\t\\t\\t\\t#\\t\\t\\t\\t\\t\n",
      "# SentiStrength_DE Version: v5 (Oct.2011) by Ha...                 OFAI \\t\\t\\t\\t\\t\n",
      "#\\t\\t\\t\\t\\t                                                                    NaN\n",
      "# SentiStrength_DE is a collection of German le...                             NaN\n",
      "# for sentiment classification together with th...                             NaN\n",
      "# (Cf. http://sentistrength.wlv.ac.uk/ ).\\t\\t\\t...                             NaN\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b74444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
